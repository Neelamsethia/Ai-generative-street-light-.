# upskill_campus

**Week Report**
**Project on AI Generative street light**
**Functionalities and data requirement**

According to the proposed web application platform made in our previous work, i.e., Deepaisarn et al. [19], the functionality of the system includes the device connection state monitoring system, environmental data dashboard, and the device disconnection detection system. In the current implementation, the essential data collected using the installed environmental sensor appears on the dashboard, as demonstrated in . The dashboard consists of the numerical and graphical format of the data, showing temperature, humidity, wind velocity, wind direction, illuminance, rain level, Ultraviolet A, and Ultraviolet B. These parameters were selected for display on the dashboard due to their roles in the analytical tasks discussed later in this article. Therefore, it was necessary to ensure that the data was collected successfully and correctly.
         The manual control system had to be available to control either each device individually or an entire device management zone. The front-end user interface was created to serve system administration and maintenance staff to interact with, and control, the devices. The back-end application programming interface (API), called the hypertext transfer protocol (HTTP), was made once the command was created and confirmed by the user. The back-end API was processed by reading the incoming device control request and its specified dimming value, and then the control command was sent and executed on the CMS API, an external control platform.
         After the device control API path is established, the automatic light adjusting system can be implemented with the usage of the prediction model on the separate data analytics platform, called SparkBeyond Discovery Platform (SparkBeyond, Netanya, Israel). The automatic system consists of two parts, the prediction model and the API path to obtain the predicted data. The prediction model created on the data analytics platform has the objective to predict future environmental conditions, based on the data collected from the environmental sensors. Therefore, the collected data must be thoroughly studied and understood. The environmental sensor data are collected every 10 min consecutively all the time. The data can be obtained using the API created by the proposed system in JavaScript Object Notation (JSON) format and later converted into Comma-Separated Value (CSV) format, which is used as inputs to train prediction models. These are time-series data, where each timestamp contains a collection of environmental values, such as temperature, humidity, rain level, and air pressure, and lighting data, such as illuminance, Ultraviolet A, and Ultraviolet B. A detailed explanation of the dataset used in the training process of the prediction model is elaborated on in the next section.
The API path for obtaining the predicted data from a prediction model with a suggested light dimming value for smart street light devices had to be created to connect with the current back-end system to build an end-to-end automated smart street light adjustment system. However, Python 3.7 and Flask python web framework  were used to develop the API path and obtain the predicted data, in order to be compatible with the data analytics platform used. The application of the flask framework can be seen in various examples, such as the back-end side of the database management system in educational institutions  After that, the prediction API path had to be hosted on the cloud platform and available to use over HTTP protocol.

**Data Analytics and Prediction Models**

Methods of performing data analytics and the prediction models for performing experiments in this work are described in this section. First of all, exploratory data analysis was carried out in order to understand the behaviors of the dataset. Then, the main experimental part, utilizing the designed AI-assisted data analytic pipeline, was performed.
5.1. Exploratory Data Analysis
The purpose of this part is to provide the main data characteristics using statistical graphics and data visualization methods. The first set of analyses examined the hourly average of illuminance value over a period of nine months, from February to October 2022, as illustrated in Figure 7. The natural light illuminance in Thailand seemed to follow a pattern wherein illuminance began to rise around 06:00, peaked in the middle of the day, and then decreased to zero at around 18:00. The correlation matrix, as shown in Figure 8, was investigated to determine the relationship between all features selected from the dataset. According to the correlation matrix, Ultraviolet A and Ultraviolet B had a strong correlation to illuminance values. Thus, these two parameters were removed from the dataset to avoid an over-fitting model. A total of five environmental parameters, including humidity, temperature, air pressure, illuminance, and wind velocity, were preserved as input parameters. The date and time were also included for use as parameters at a training timestamp.
AI-Assisted Data Analytics
Five environmental parameters were included in the data analytics in exploratory data analysis. A data-driven scheme was utilized to empower the management of our smart lighting system by building up models to make better decisions based on intuitive insights. Functionalities in the SparkBeyond Discovery platform (SparkBeyond, Israel) were adopted to provide an AI-driven engine as a tool for extraction of meaningful features and to perform experiments on various machine learning models to learn and solve the time-series problem. The tool has been successfully applied in many research works to gain insight and create efficient models [28,29,30], as well as several industrial applications, ranging from banking, and electronic commerce, to insurance.
**Dataset**

In this work, the target variable to be predicted by a time-series model was a future natural illuminance value at a specific timestamp. The dataset was collected from the environmental sensors, which were stored in the external platform database and imported via the API [19]. The environmental values from February 2022 to October 2022, were used to train and test the prediction model. The original parameters included humidity, temperature, air pressure, illuminance, wind velocity, and date and time at 10-min intervals. The dataset was cleaned prior to model training.

**Experimental Pipeline**

First and foremost, hundreds of thousands of features were synthesized from the original parameters in the dataset. The extracted features were then ranked according to their importance, which was assessed using the relative information gain (RIG). Only 50 potential features (out of the 28 million extracted features) were kept for further analyses based on the predetermined feature count that provided significant RIG. After that, the AutoML function available in the SparkBeyond platform [31] was applied so that it generated an optimized predictive model in terms of accuracy and computational costs. The dataset was split into 80% for training and 20% for testing. The next illumination value with a one-day gap was defined as the target in the training phase. In this work, the SciKitLearn standard ML algorithms, consisting of Gradient Boosting, XGBoost, Random Forest, and Decision Tree, were taken into consideration during the model selection process.

**Evaluation**

For information retrieval, the relative information gain (RIG) was used as the evaluation metric for the feature importance. For model selection, the forecast performance was evaluated by analyzing the characteristics of predicted versus actual illuminance values. Two evaluation metrics were observed. Firstly, the correlation coefficient was calculated to find the relationship between the predicted and the actual values. Secondly, the residual between the predicted and the actual value was computed. Both metrics gave us the trend of the over- and under-prediction characteristics of the models:

**Result**
In general, a model performs better when it has a higher correlation coefficient between predicted and actual values. The results suggested that the optimal model varied depending on the size of the analysis window. For example, the XGBoost model performed the best among the selected models given a window size of 3 days, yielding the highest correlation coefficient of 0.922. However, at a window size of 7 days, the Random Forest model performed better than others, yielding the highest correlation coefficient of 0.918. Moreover, it appeared that the Decision Tree model consistently had the worst performance, yielding the lowest correlation coefficient for all window sizes. It was possible that the Decision Tree was potentially overfitted, resulting in poor performance in predicting from unseen data.
